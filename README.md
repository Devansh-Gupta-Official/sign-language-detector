# Sign Language Detector using MediaPipe and LSTM Neural Network
This repository contains code for a sign language detection system utilizing the MediaPipe library for pose and hand tracking, combined with a Long Short-Term Memory (LSTM) Neural Network for classification.

## Overview
The project includes:

- code.ipynb: Jupyter Notebook containing the code for data collection, preprocessing, model training, and live testing of the sign language detector.
- action.h5: Saved model file after training the LSTM Neural Network.
- MP_data: Directory to store collected keypoints data for training and testing.
- Logs: Folder for TensorBoard logs to monitor neural network progress.

## Setup and Requirements
